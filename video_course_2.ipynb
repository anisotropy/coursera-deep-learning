{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coursera - Deep Learning Course 2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-ddWhvu2sgFE",
        "EGdda0SksvwP",
        "mewxegr_s-q2",
        "x-dAc0HOtObc",
        "vQuqrqMwtobf",
        "RGW361r2to05",
        "Y4NqSBa4uFix",
        "vWmYHAqvuFoc",
        "QKe12j3GuFtW",
        "X2gHmHCz62mv",
        "eLa08SUm5Oop",
        "5bd-0uqvDWwg",
        "wa5ahxlTDIEx",
        "3aq_dIDCSqEI",
        "fan5v0S_SqIc",
        "wQDkLwNGSqMV",
        "wKh8GJ2She7h",
        "mtxH3qI3he_x",
        "-0cSSp0rhfE7",
        "45gEgafIhfYc",
        "Z_iHofBwiici",
        "5dvRavI1iie5",
        "LZuD6dOPOh-_",
        "6XLMiFs9iij5",
        "T0S79QLZiinK",
        "2dKB9Hbmiip7",
        "D97UD5Bsiisz",
        "eqyDd71Fiive",
        "KsHM5F3yiiyG",
        "Jr1iD0K78nqn",
        "nXbOgs0A8nt1",
        "cyQiaLmDNsYB",
        "_IFEuCiPeqtz"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBjnZTeS62gy"
      },
      "source": [
        "# Course 2 — Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySUB_A-F62kh"
      },
      "source": [
        "## Week 1 — Practical Aspects of Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ddWhvu2sgFE"
      },
      "source": [
        "### Train / Dev / Test sets\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-WIanVvs4J2"
      },
      "source": [
        "- 데이터의 bias를 고려할 필요가 없다면 test set은 없어도 된다.\n",
        "- 데이터의 수가 100만개 이상이라면, training set, dev set, test set의 비율은 98: 1: 1 정도로, training set 의 비율을 아주 크게 잡는다. 데이터의 수가 적다면 training set 을 70%로 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGdda0SksvwP"
      },
      "source": [
        "### Bias / Variance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HdTFmHRtKj_"
      },
      "source": [
        "- high variance(overfitting)\n",
        "    - train set error가 optimal error에 가깝지만, dev set error 가 train set error 와 차이가 많이 날 경우\n",
        "    - ex) training set error: 1%, dev set error: 11%\n",
        "- high bias(underfitter)\n",
        "    - train set error 가 optimal error에서 멀지만, dev set error는 train set error와 차이가 크지 않은 경우\n",
        "    - ex) training set error: 15%, dev set error: 16%\n",
        "- optimal error는 Bayesian optimal error라고 부르기도 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mewxegr_s-q2"
      },
      "source": [
        "### Basic Recipe for Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oPcEPs0tOAY"
      },
      "source": [
        "- train set 으로 high bias인지 확인. bias를 줄이기 위해, bigger network 사용하고, longer train 한다.\n",
        "- dev set으로 high variance인지 확인. variance를 줄이기 위해 more data, regularization 사용.\n",
        "- low bias, low variance 될 때까지 learning\n",
        "- 빅데이터, 딥러닝 시대에서는 bias와 variance이 더 이상 trade-off의 관계가 아니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-dAc0HOtObc"
      },
      "source": [
        "### Regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBXHtjCDtoE6"
      },
      "source": [
        "- 데이터를 추가하지 않고 variance 를 줄이기 위해서 cost function에 regularization을 추가할 수 있다.\n",
        "- L2 regularization(자주 사용됨): $\\frac{\\lambda}{2m} \\lVert w \\rVert^2$ ($\\lambda$: regularization parameter)\n",
        "- L1 regularization: $\\frac{\\lambda}{2m} \\lVert w \\rVert$\n",
        "- L2 regulaization 는 'weight to decay'라고도 불린다. 왜냐하면 weight 가 $(1- \\alpha \\frac \\lambda m)$의 비율로 감소하기 때문이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQuqrqMwtobf"
      },
      "source": [
        "### Why regularization reduces overfitting?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeOLWy_0topc"
      },
      "source": [
        "- regularization이 variance를 감소시키는 이유: regularization parameter 가 아주 크다면 weight 중 많은 부분이 0에 가까워 지고, 그것은 hidden layer 의 unit 수가 줄어든다는 것을 의미한다. 그렇게 되면 NN의 복잡도가 감소하게 되고, NN 전체에 대한 함수는 linear function에 가깝게 되므로 variance를 감소시키는 효과를 가져온다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGW361r2to05"
      },
      "source": [
        "### Dropout Regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNT_-dUsto_B"
      },
      "source": [
        "- Dropout: 일정한 확를로 neuron을 제거하는 regularization 기법. 각 interation, 각 sample 마다 제거되는 neuron은 달라진다.\n",
        "- Inverted dropout: 가장 많이 사용되는 dropout 기법으로, activation value의 평균값을 유지하기 위해 각 iteration의 마지막 단계에서, '유지할 확률'로 activation value를 나누어 준다.\n",
        "- 결과가 일정하지 않기 때문에, 테스트 단계에서는 dropout을 사용하지 않는다.\n",
        "- dropout의 가장 큰 단점은, cost function이 정의될 수 없기 때문에, 디버깅을 하기 어렵다는 사실이다. 디버깅을 위해서는 dropout을 제거한 후에 cost가 점차적으로 감소하는지 확인하면 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGa1vmbcif1C"
      },
      "source": [
        "### Understanding Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4NqSBa4uFix"
      },
      "source": [
        "### Other regularization methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgYjkX5tuFlp"
      },
      "source": [
        "- Data augmentation: 컴퓨터 비전에서 주로 사용하는 regularization 기법이다. 이미지를 회전하거나 왜곡시키는 등의 작업을 통해 데이터 부족으로 인한 overfitting을 완화시킬 수 있다.\n",
        "- Early stopping: iteration에 대한 train set error와 dev set error의 그래프를 함께 그려서 dev set error 가 다시 증가하는 지점을 찾는다. 이 기법은 추가적인 hyperparameter가 필요없다는 장점이 있다. 하지만 cost를 최소화하는 것과, overfitting을 줄이는 것은 서로 독립적인 작업일 수 있는데, 이 기법은 이 두 작업을 함께 수행함으로써 최적화를 방해할 수 있다는 단점이 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWmYHAqvuFoc"
      },
      "source": [
        "### Normalizing inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yC29rwouFrE"
      },
      "source": [
        "- NN을 빠른 시간에 최적화하기 위해서는 normalization이 필요하다.\n",
        "- Normailzation: $(x - \\mu) / \\sigma^2$\n",
        "    - $\\mu$: mean, $\\sigma$: variance\n",
        "    - mean과 variance는 전체 sample에 대한 하나의 feature에 대한 것이다.\n",
        "- normalization을 해야 하는 이유: cost function의 contour가 매우 spherical하게 되기 때문에 minimum cost를 더 빨리 찾을 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKe12j3GuFtW"
      },
      "source": [
        "### Vanishing / Exploding gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9DdgKLD8aL0"
      },
      "source": [
        "- activation function이 linear하고 b=0일 경우(예를 들어, $a(x) = wx$), $\\hat y$는 layer의 수에 따라 기하급수적으로\u001d 증가하거나 감소하기 때문에, 이 경우 gradients가 vanishing하거나 exploding할 수 있다.\n",
        "- 이 문제는 DNN에서 오랫동안 큰 문제였다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2gHmHCz62mv"
      },
      "source": [
        "### Weight Initialization for Deep Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWzOVLJA9PoM"
      },
      "source": [
        "- $b=0$인 single neuron network를 생각해보자: $z = w_1x_1 + \\dots + w_nx_n$, $a = g(z)$\n",
        "     - vanishing/exploding gradient를 (완벽한 방법은 아니지만) 방지하기 위해서는, $n$이 클수록 $w$도 작아지는 것이 좋기 때문에, random하게 초기화된(starndard normal distribution) $w$의 variance를 $1/n$으로 만들어주기 위해, $w$에 $\\sqrt{1/n}$으로 곱해줄 필요가 있다.\n",
        "- $g(z)$이 ReLU인 경우에는, varicance를 $2/n$으로 설정하는 것이 더 효과적이다.\n",
        "- $g(z)$이 $tanh$인 경우에는, varicance를 $1/n$으로 설정하는 것이 더 효과적이다(Xavier initailization).\n",
        "- variance를 $\\sqrt{2/(n^{[l-1]} + n^{[l]})}$로 설정하기를 권하는 논문도 있다.\n",
        "- variance도 조정해야 할 hyperparameter이다. 하지만 다른 hyperparameter에 배해 상대적으로 덜 중요하다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLa08SUm5Oop"
      },
      "source": [
        "### Numerial Approximation of Gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBtBChG-4R-s"
      },
      "source": [
        "- $(f(\\theta + \\epsilon) - f(\\theta - \\epsilon)) / {2\\epsilon} \\approx f^\\prime(\\theta), error=O(\\epsilon^2)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bd-0uqvDWwg"
      },
      "source": [
        "### Gradient Checking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtwUhgYbD1O1"
      },
      "source": [
        "- $d\\theta_{approx}^{[i]} = (J(\\theta_1, \\cdots, \\theta_i + \\epsilon, \\cdots) - J(\\theta_1, \\cdots, \\theta_i - \\epsilon, \\cdots)) / 2\\epsilon$\n",
        "- $d\\theta^{[i]}=\\partial J / \\partial \\theta_i$\n",
        "- Check $\\lVert d\\theta_{approx} - d\\theta \\rVert_2 / (\\lVert d\\theta_{approx} \\rVert_2 + \\lVert d\\theta \\rVert_2) \\approx \\epsilon$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa5ahxlTDIEx"
      },
      "source": [
        "### Gradient checking implementation notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve9N2zRYDIHw"
      },
      "source": [
        "- Don't use in training -- only to debug: $d\\theta_{approx}$ is very slow computation\n",
        "- If algorithm fails grad check, look at components to try to identify the bug.\n",
        "- Remember regularization.\n",
        "- Don't work with dropout.\n",
        "- Run at random initialization; perhaps again after some training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mci8BjH2SUrL"
      },
      "source": [
        "## Week 2 — Optimization Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aq_dIDCSqEI"
      },
      "source": [
        "### Mini-Batch Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ckB-r4DSqGR"
      },
      "source": [
        "- Vectorization allows you to efficiently compute on *m* examples. 하지만 *m*이 너무 크면 계산 속도가 느릴 수 밖에 없다.\n",
        "- mini-batch: $X^{\\{t\\}}, Y^{\\{t\\}}$\n",
        "- 1 step of gradient descent using $X^{\\{t\\}}, Y^{\\{t\\}}$\n",
        "- 1 epoch: 1 pass through the whole training set\n",
        "- 1 epoch = m / (size of mini-batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fan5v0S_SqIc"
      },
      "source": [
        "### Understanding Mini-batch Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hC47jISSSqKa"
      },
      "source": [
        "- mini-batch 의 경우에는 1 step이 1 iteration이 되고, sample의 수가 적어지는 효과가 있기 때문에, 학습 속도가 빨라진다. 하지만 cost function의 oscillation이 증가한다.\n",
        "- mini-batch size가 너무 작으며 vectorization에 의한 학습 속도 상승의 효과가 없기 때문에, 전체적인 학습 속도가 빠르지 않고, cost의 최소값에 도달하지 못할 수도 있기 때문에 적당한 값을 선택해야 한다.\n",
        "- mini-batch size = 1(stochastic gradient descent): lose speed-up by vectorization. big oscillation(noise)\n",
        "- mini-batch size = m: too long time per iteration\n",
        "- Choosing mini-batch size\n",
        "    - If small training set(m < 2000), mini-batch size = m\n",
        "    - Typical mini-batch size = 64, 128, 256, 512 (power of 2)\n",
        "    - Make sure mini-batch size fit in CPU/GPU memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQDkLwNGSqMV"
      },
      "source": [
        "### Exponentially Weigted Averages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zl_xh320he43"
      },
      "source": [
        "- exponentially weighted average(or running average)$ $\n",
        "    - $v_t = \\beta v_{t-1} + (1-\\beta) \\theta_t, ~0 < \\beta < 1$\n",
        "    - $v_t$: average over $\\backsim 1/(1-\\beta)$ entries\n",
        "- $\\beta$가 크면 plot은 smooth해지지만, 오른쪽으로 shift되고, 변화에 빨리 적응하지 못한다.\n",
        "- $\\beta$는 learning algorithm에서의 hyperparamter이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKh8GJ2She7h"
      },
      "source": [
        "### Understanding Exponentially Weighted Averages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAHCJFrRhe9u"
      },
      "source": [
        "- $v_t = (1-\\beta)\\theta_t + (1-\\beta) \\beta \\theta_{t-1} + (1-\\beta) \\beta^2 \\theta_{t-2} + \\cdots$\n",
        "- 현시점보다 과거의 데이터일 수록 현시점의 데이터에 미치는 영향이 exponetially 감소한다.\n",
        "- $\\beta^n$이 $0.5(\\approx 1/e)$이 되는 지점까지가 현시점의 데이터에 영향을 미친다고 할 수 있기 때문에, $n \\approx 1/(1-\\beta)$이다.\n",
        "    - $1/e \\approx (1 - \\beta)^{1/(1-\\beta)},~\\beta \\approx 1$ ($ e \\equiv \\lim\\nolimits_{n\\to \\infty} (1 + 1/n)^n $)\n",
        "- 일반적인 moving average가 average를 더 정확하게 계산하지만, exponentially weighted average는 메모리가 적게 필요하고, 계산 속도가 빠르다는 장점이 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtxH3qI3he_x"
      },
      "source": [
        "### Bias Correction of Exponentially Weighted Averages\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8moC9KLLhfCS"
      },
      "source": [
        "- $v_t$를 $1-\\beta^t$로 나누어 준다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0cSSp0rhfE7"
      },
      "source": [
        "### Gradient Descent With Momentum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jr-2MvshfVp"
      },
      "source": [
        "- Gradient descent with momentum is more fater algorithm then greadient descent: averaging을 통해 cost function의 oscillation을 완화시켜준다.\n",
        "- On iteration $t$:\n",
        "    - Compute $dw$, $db$ on current mini-batch\n",
        "    - $v_{dw} \\leftarrow \\beta v_{dw} + (1-\\beta)dw, ~ v_{db} \\leftarrow \\beta v_{db} + (1-\\beta)db$\n",
        "    - $W \\leftarrow W - \\alpha v_{dw}, ~ b \\leftarrow b - \\alpha v_{db} $\n",
        "- In practice, $\\beta=0.9$\n",
        "- bias correction은 일반적으로 사용하지 않는다. 10 iteration 이후에는 $1-\\beta^t$가 1에 가까워지기 때문이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45gEgafIhfYc"
      },
      "source": [
        "### RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awIuKooPhfan"
      },
      "source": [
        "- RMSprop: root mean squre prop\n",
        "- On iteration $t$: ($db$에 대해서도 동일하게)\n",
        "    - Compute $dw$ on current mini-batch\n",
        "    - $s_{dw} \\leftarrow \\beta s_{dw} + (1-\\beta)dw^2$ (use element-wise squre)\n",
        "    - $W \\leftarrow W - \\alpha (dw) / (\\sqrt{s_{dw}} + \\epsilon)$\n",
        "- ${dw}/\\sqrt{s_{dw}}$: $dw$가 큰 경우 $W$의 증감량을 감소시켜 oscillation을 줄이는 효과가 있다.\n",
        "- $\\epsilon$은 분모가 0이 되지 않도록 방지하는 역할을 하며, $10^{-8}$ 정도로 작은 값을 설정한다.\n",
        "- With RMSprop you can user larget learning rate.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_iHofBwiici"
      },
      "source": [
        "### Adam Optimization Algorithm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR80LC_19ZIu"
      },
      "source": [
        "- Adam(Adaptive Momentum Estimation) Optimization: momentum + RMSprop. 매우 효과적이고 다양한 NN에서 성능을 발휘한다는 것이 증명되었다.\n",
        "- On iteration $t$: ($db$에 대해서도 유사하게)\n",
        "    - Compute $dw$ on current mini-batch\n",
        "    - $v_{dw} \\leftarrow \\beta_1 v_{dw} + (1-\\beta_1)dw$\n",
        "    - $s_{dw} \\leftarrow \\beta_2 s_{dw} + (1-\\beta_2)dw^2$ (use element-wise squre)\n",
        "    - $v_{dw}^{corrected} = v_{dw} / (1-\\beta_1^t)$\n",
        "    - $s_{dw}^{corrected} = s_{dw} / (1-\\beta_2^t)$\n",
        "    - $W \\leftarrow W - \\alpha v_{dw}^{corected} / (\\sqrt{s_{dw}} + \\epsilon)$\n",
        "- Hyperparameters:\n",
        "    - $\\alpha$: need to tune\n",
        "    - $\\beta_1$: 0.9 is default\n",
        "    - $\\beta_2$: 0.999 is recommended\n",
        "    - $\\epsilon$: $10^{-8}$ is recommended"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dvRavI1iie5"
      },
      "source": [
        "### Learning Rate Decay\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onWArognGXD5"
      },
      "source": [
        "- 학습 속도를 높이는 방법 중 하나는 learning rate를 점차로 감소시키는 것이다. 이러한 방법을 learning rate decay라고 부른다.\n",
        "- $\\alpha = \\alpha_0 / (1 + decay~rate \\times epoch )$\n",
        "- Other learning rate decay methods: $ $\n",
        "    - $\\alpha = 0.95^{epoch}\\alpha_0$ -- exponentialy deday\n",
        "    - $\\alpha = (k/\\sqrt{epoch})\\alpha_0$, or $\\alpha = (k/\\sqrt{t})\\alpha_0$, $k$ is constant\n",
        "    - discrete: for example, 0.1 for t < 10, 0.9 for t < 20, etc.\n",
        "    - manual decay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZuD6dOPOh-_"
      },
      "source": [
        "### The Problem of Local Optima"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88x8XhQ2Oqns"
      },
      "source": [
        "- 딥러닝의 초기에는 local optima에 대해 걱정이 많았다. 하지만 실제로는 saddle point는 많지만 local optima는 거의 없다. 왜냐하면 $dw$의 dimension이 굉장히 크기 때문에, $dw$의 모든 요소가 0이 될 확률은 아주 작기 때문이다.\n",
        "- plateaus(0에 가까운 derivative가 long iteration동안 계속 되는 지역\u001f)가 학습 속도를 느리게 만들 수 있다. momentum과 Adam 알고리즘에 이러한 경우에 도움을 줄 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZmTzYw9iihZ"
      },
      "source": [
        "## Week 3 — Hyperparameter Tunning \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XLMiFs9iij5"
      },
      "source": [
        "### Tuning Process\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gu6wyY8dZ_Mo"
      },
      "source": [
        "- Hyperparameters (tunning할 필요성이 높은 순서대로):$ $\n",
        "    1. $\\alpha$\n",
        "    2. $\\beta$, mini-batch size, no. of hidden units\n",
        "    3. no. of layers, learning rate decay\n",
        "    4. , $\\beta_1$, $\\beta_2$, $\\epsilon$\n",
        "- Tunning Process\n",
        "    1. 각 HP(hyperparameter)에 대해, 일정한 개수의 random한 값들을 설정한 다음 테스트해본다.\n",
        "    2. 학습 성능이 좋게 나오는 HP의 집합을 알아낸 다음, 그 범위 내에서 1번의 과정을 반복한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0S79QLZiinK"
      },
      "source": [
        "### Using an Appropriate Scale to Pick Hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9o5jS0Igwh8"
      },
      "source": [
        "- no. of hidden units 와 no. of layers 에 대해서는 linear scale을 사용해 sampling할 수 있다.\n",
        "- learning rate의 경우(ex. 0.001 ~ 1): log scale을 사용해 sampling하는 것이 더 합리적이다.\n",
        "- $\\beta$의 경우(ex 0.9~0.999): 에는 $1-\\beta$에 대해서 log scale을 사용해 sampling한 다음, 다시 $\\beta$를 계산한다. ($1/(1-\\beta)$가 average를 구하는 데이터의 개수를 의미하기 때문)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dKB9Hbmiip7"
      },
      "source": [
        "### Hyperparameter Tuning in Practice: Pandas vs. Caviar\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEzAwmscvMDf"
      },
      "source": [
        "- Intuitions do get stale. Re-evaluate occasionally.\n",
        "- Baby sitting one model\n",
        "    - computational resource가 부족할 때 사용.\n",
        "    - 하나의 모델에 대해, iteration에 따른 cost의 추이를 살펴가면서 hyperparameter를 변경.\n",
        "- Training many models in parallel\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D97UD5Bsiisz"
      },
      "source": [
        "### Normalizing Activation in a Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSI2B0tTD4EZ"
      },
      "source": [
        "- Batch normalization makes hyperparameter search much easier.\n",
        "- hidden layer의 input에 대해서도 normalization. 일반적으로 $a$가 아니라 $z$를 normalize한다.\n",
        "- Implementing Batch Norm $ $\n",
        "    - Given some intermediate values in NN, $z^{[l]\\(1\\)},\\cdots,z^{[l]\\(m\\)}$\n",
        "    - $z_{norm}^{[l]\\(i\\)} = (z^{[l]\\(i\\)} - \\mu^{[l]}) / \\sqrt{\\sigma^{[l]2} + \\epsilon}$ \n",
        "    - $\\tilde{z}^{[l]\\(i\\)} = \\gamma^{[l]} z_{norm}^{[l]\\(i\\)} + \\beta^{[l]}$ (mean이 0, variacne가 1이기를 원하지 않는다면)\n",
        "- 예를 들어, activation fuction이 sigmoid라면, 1보다는 더 큰 variacne가 되기를 원할 것이다. \n",
        "- $\\gamma$ and $\\beta$ are also learnable parameters of the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqyDd71Fiive"
      },
      "source": [
        "### Fitting Batch Norm Into Neural Network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WRGNi5KOBNG"
      },
      "source": [
        "- $X \\rightarrow Z^{[1]} \\xrightarrow[{BN}]{\\gamma^{[1]}, \\beta^{[1]}} \\tilde{Z}^{[1]} \\rightarrow a^{[1]} \\rightarrow Z^{[2]} \\rightarrow \\cdots$\n",
        "- Parameters: $W^{[l]}, \\gamma^{[l]}, \\beta^{[l]}$ (batch norm에 의해 mean이 0가 되기 때문에, $b^{[l]}$은 제거될 수 있다.)\n",
        "    - $W^{[l]} \\leftarrow W^{[1]} - \\alpha dW^{[l]}$\n",
        "    - $\\beta^{[l]} \\leftarrow \\beta^{[1]} - \\alpha d\\beta^{[l]}$\n",
        "    - $\\gamma^{[l]} \\leftarrow \\gamma^{[1]} - \\alpha d\\gamma^{[l]}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsHM5F3yiiyG"
      },
      "source": [
        "### Why Does Batch Norm Work?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfAZTCS6ZiUJ"
      },
      "source": [
        "- 첫번째 이유는 input의 normalization과 동일하게, batch norm을 사용하면 const function의 contour가 원에 가까워진다는 것이다.\n",
        "- 두번째 이유는 batch norm을 사용하면, layer의 input data($a^{[l-1]}$)의 분포가 변하더라도(covariate shift) mean과 variance는 일정한 수준으로 유지되기 때문에, 이전 layer의 영향을 적게 받는다는 것이다. 다르게 말하면, input data의 데이터 분포가 어느 정도 일정하게 유지되기 때문에 학습속도가 빨라 질 수 있는 것이다.\n",
        "- Batch Norm as regularization\n",
        "    - Each mini batch is scaled by the mean/variance computed of that mini-batch. (그래서 mean/variance에 noise가 생기고, 이것은 $z$에 noise가 생기는 것으로 이어진다.)\n",
        "    - This adds some noise to the values $z^{[l]}$ within that mini-batch. So similar to dropout it adds some noise to each hidden layer's activations.\n",
        "    - This has a slight regularization effect. 그리고 mini-batch size가 클수록 regularization 효과가 떨어진다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jr1iD0K78nqn"
      },
      "source": [
        "### Batch Norm At Test Time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXbOgs0A8nt1"
      },
      "source": [
        "- training 단계에서와는 다르게 test 단계에서는 sample을 한번에 하나씩 처리해야 하기 때문에, mean과 variance를 구할 수 없다. 따라서 training 단계에서 계산한 mean과 variance를 test 단계에서 사용한다.\n",
        "- $\\mu$, $\\sigma^2$: estimate using exponentially weighted average (across mini-batches $\\mu^{\\{t\\}[l]}$, $\\sigma^{2\\{t\\}[l]}$)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyQiaLmDNsYB"
      },
      "source": [
        "### Softmax Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xQlXt8Dj9FL"
      },
      "source": [
        "- C = no. of classes, dimension of the last layer: (C, 1)\n",
        "- Example of the last layer: $P(others|x)$, $P(cat|x)$, ...\n",
        "- Activation Function of Softmax Layer: $a_i^{[L]}=t_i / \\sum_i{t_i}, ~ t_i=e^{z_i^{[L]}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IFEuCiPeqtz"
      },
      "source": [
        "### Training Softmax Classifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruXX-UpiypVG"
      },
      "source": [
        "- Softmax regression generalizes logistic regression to C classes\n",
        "- Loss Function: $L(\\hat{y}, y)= - \\sum_j^C{y_j}\\log{\\hat{y}_j}$\n",
        "- Cost Function: $J=(1/m)\\sum_i^m{L(\\hat{y}^{(i)}, y^{(i)})}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brWhHDHhjMcU"
      },
      "source": [
        "### Deep Learning Frameworks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7miuDKZeq3g"
      },
      "source": [
        "### Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZD_bs-syrN9"
      },
      "source": [
        "Simple Example: $J = w^2 - 10w + 25$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjmwi3qa2NxJ"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "w = tf.Variable(0, dtype=tf.float32)\n",
        "cost = w**2 - 10*w + 25\n",
        "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "session = tf.Sesssion()\n",
        "session.run(init)\n",
        "print(session.run(w))\n",
        "\n",
        "for i range(1000):\n",
        "    session.run(train)\n",
        "print(sessoin.run(w))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4OkEGwL8LxT"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "coefficients = np.array([[1.], [-10.], [25.]])\n",
        "\n",
        "w = tf.Variable(0, dtype=tf.float32)\n",
        "x = tf.placeholder(tf.float32, [3, 1])\n",
        "cost = x[0][0]*w**2 + x[1][0]*w + x[2][0]\n",
        "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "session = tf.Sesssion()\n",
        "session.run(init)\n",
        "print(session.run(w))\n",
        "\n",
        "for i range(1000):\n",
        "    session.run(train, feed_dict={x: coefficients})\n",
        "print(sessoin.run(w))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}