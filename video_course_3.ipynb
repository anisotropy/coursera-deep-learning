{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coursera - Deep Learning Course 3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tU_Dti3-FzOG",
        "mvqK742MF-ES",
        "6JHO5TWXF-Gj",
        "gH1dOItmF-Jc",
        "cJD8QEk4F-Li",
        "cApWr6q1SVyk",
        "dYm9-qsHSV1m",
        "C9c2hrsUSV5F"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucpNR4O9gIho"
      },
      "source": [
        "# Course 3 — Structuring Machine Learning Projects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2fcPaNMgIjm"
      },
      "source": [
        "## Week 1 — ML Strategy (1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG_HMgtkjcgn"
      },
      "source": [
        "### Why ML Strategy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTddGrNEA5qy"
      },
      "source": [
        "- Ideas $~$\n",
        "    - Collect more data\n",
        "    - Collect more diverse training set\n",
        "    - Training algorithm longer with gradient descent\n",
        "    - Try Adam instead of gradient descent\n",
        "    - Try bigger network\n",
        "    - Try smaller network\n",
        "    - Try dropout\n",
        "    - Add $L_2$ regularization\n",
        "    - Network architecture: activation function, no. of hidden units\n",
        "    - ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNYZFY44gInM"
      },
      "source": [
        "### Orthogonalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GljWf-4cDA6U"
      },
      "source": [
        "- orthogonalization: 하나의 knot(control)이 하나의 특성을 조정하는데에만 영향을 주는 것\n",
        "- Chain of assumptions in ML\n",
        "    1. Fit training set well on cost function: bigger network, other optimization algorithm\n",
        "    2. Fit dev set well on cost function: regularization, bigger training set\n",
        "    3. Fit test set well on cost function: bigger dev set\n",
        "    4. Perform well in real world: change dev set or cost function\n",
        "- 예를 들어, training set error을 줄이기 위해서는, network 수를 조정하거나 optimization algorithm을 조정하고, dev set error 를 줄이기 위해서는 regularization을 추가하거나 bigger trainig set을 이용하는 방식으로, 등등\n",
        "- early stoping 기법은 training set error와 dev set error에 모두 영향을 줄 수 있기 때문에 -- othogonality를 해치기 때문에 -- 권장하지 않는다. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqkNAOd4gIpF"
      },
      "source": [
        "### Single Number Evaluation Metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQJTo5CoP1w9"
      },
      "source": [
        "- Example $ $\n",
        "    - Precision: percentage of true cat in the recognized result\n",
        "    - Recall: percentage of true recognition cat of the all cat predictions\n",
        "    - precision과 recall은 보통 trade-off 관계이다.\n",
        "    - precision과 recall이라는 두 가지 metric으로 평가를 하면 판단하기가 어렵기 때문에, F1 score를 사용한다. $2/(1/P + 1/R)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga-M7pocgIq7"
      },
      "source": [
        "### Satisficing and Optimizing Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vId0Nn0UAht"
      },
      "source": [
        "- 예를 들어, Accuracy와 running time 을 모두 고려해야 할 때: maximize accuracy (optimizing) subject to running time < 100ms (satisfying)\n",
        "- N metrics: 1 optimizing, N-1 satifying"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI3Ns5oGgyn3"
      },
      "source": [
        "### Train/Dev/Test Set Distributions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ_uSqykWfbZ"
      },
      "source": [
        "- Example: Cat classification dev/test set\n",
        "    - bad idea:\n",
        "        - dev set: US, UK, Othr Europe, South America\n",
        "        - test set: India, China, Other Asia\n",
        "        - because come from different distriutions\n",
        "    - 모든 지역에 대해 무작위로 dev set 과 test set을 선택해야 한다.\n",
        "- Guideline: choose a dev set and test set to reflect data you expect to get in the future and consider important to do well on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xBLjZCJgyqc"
      },
      "source": [
        "### Size of Dev and Test Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FJ1Cep6elzf"
      },
      "source": [
        "- Old way of splitting data\n",
        "    - train: 70%; test: 30\n",
        "    - train: 60%; dev: 20; test: 20\n",
        "- modern ML (size of data > 1,000,000)\n",
        "    - train: 98%; dev: 1%; test: 1%\n",
        "- Size of test set: set your test set to be big enough to give high confidence in the overall performance of your system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR5WiDfSgysl"
      },
      "source": [
        "### When to Change Dev/Test Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xWIAjD5h67k"
      },
      "source": [
        "- New metric of error (exmaple) $ $\n",
        "    - Error: $(\\sum_i{w^{(i)}}) \\sum_i^{m_{dev}} w^{(i)} I(y_{pred}^{(i)} \\not = y^{(i)} )$\n",
        "    - $I = 1$ for true, $I=0$ for false\n",
        "    - $w^{(i)} = 1$ for suitable sample and $w^{(i)} = 10$ for not suitable sample.\n",
        "- Two steps of ML (analogy of shooting)\n",
        "    1. Place the target (suitable metric)\n",
        "    2. Aim at the target (training for good metric)\n",
        "- Guidline: if doing well on your metric + dev/test set does not correspond to doing well on your application, change your metric and/or dev/test set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N8BeHjIgyuP"
      },
      "source": [
        "### Why Human-level Performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7AGZHIPuj2v"
      },
      "source": [
        "- Theoretical optimum level of performace: Bayse optimal error\n",
        "- Why compare to human-level performance. Humans are quite good at a lot of tasks. So long as ML is worse than humans, you can:\n",
        "    - Get labels data from humans.\n",
        "    - Gain insight from manual error analysis: Why did a person get this right?\n",
        "    - Better analysis of bias/variance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODnYM3hygyv7"
      },
      "source": [
        "### Avoidable Bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzgZha04wk6j"
      },
      "source": [
        "- Human: 1%, Train: 8%, Dev: 10% — focus on bias\n",
        "- Human: 7.5%, Train: 8%, Dev: 10% — focus on variance (overfitting)\n",
        "- Avoidable bias: trainig error - Human error(or Bayse error)\n",
        "- Variance: dev error - training error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxCeMV7mFbuR"
      },
      "source": [
        "### Understanding Human-level Performance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4QTAPUUz1K-"
      },
      "source": [
        "- Human-level error as a proxy for Bayse error\n",
        "- Exampe: what is “human-level”?\n",
        "    - Typical human: 3%\n",
        "    - Typical doctor: 1%\n",
        "    - Experienced doctor: 0.7%\n",
        "    - Team of experienced doctors: 0.5%\n",
        "- 성취하고자하는 목적에 따라 human-level erorr는 0.5%도, 1%, 0.7%도 될 수도 있다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5QYhzBlFby8"
      },
      "source": [
        "### Surpassing Human-level Performance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dREFBIOd5lq_"
      },
      "source": [
        "- Human error: 0.5%; train error: 0.3%; dev error: 0.4%\n",
        "    - Bayse error가 0.3%보다 작다는 것의 의미하는가, 아니면 overfitting이라는 걸 의미하는가?\n",
        "    - Avoidable bias를 줄여야 하는가, 아니면 variance를 줄여야 하는가?\n",
        "- Problems where ML significantly surpasses human-level performance\n",
        "    - Online advertising\n",
        "    - Product recommendation\n",
        "    - Logistics (predicting transit time)\n",
        "    - Loan approvals\n",
        "- Structural data에 대한 ML이 natural perception data의 경우보다, 더 쉽게 human-level을 능가할 수 있다.\n",
        "- 또한 위의 예시들이 사람보다 더 많은 데이터를 확보할 수 있다.\n",
        "다음의 경우는 natural perception task인데도, human level을 능가한다.\n",
        "    - Speech recognition\n",
        "    - Some image recognition\n",
        "    - Medical task\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2MNNWq5Fb13"
      },
      "source": [
        "### Improving your Model Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPw2BRM8-5_5"
      },
      "source": [
        "- The two fundamental assumptions of supervised learning\n",
        "    - You can fit the training set pretty well.\n",
        "    - The training set performance generalizes pretty well to the dev/test set.\n",
        "- Reducing (avoidable) bias and variance\n",
        "    - Avoidable bias\n",
        "        - Training bigger model\n",
        "        - Train longer/better optimization algorithms\n",
        "        - NN architecture/hyperparameters search\n",
        "    - Variance\n",
        "        - More data\n",
        "        - Regularization\n",
        "        - NN architecture/hyperparameters search\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wN8VxMmFzLJ"
      },
      "source": [
        "## Week 2 -- ML Strategy (2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tU_Dti3-FzOG"
      },
      "source": [
        "### Carrying Out Error Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsjulYSUBS4c"
      },
      "source": [
        "- 예를 들어, 고양이 classifier의 결과에서 고양이로 잘못 판단한 개 사진들이 발견되었다고 가정하자. 그 경우, 더 많은 개 사진을 모으거나, 개에게만 특정된 특정을 필터링할 수 있다. 하지만 성능 향상을 위한 작업을 시작하기 전에 이 작업이 얼만큼 큰 효과를 낼 수 있는지 미리 알 수 있는 방법은 없을까?\n",
        "- 예를 들어, 성능 향상을 하기 전 classifier의 error가 10%이고, 잘못 분류된 사진 100개 중에 개 이미지가 5개 뿐이라면, 우리가 기대할 수 있는 error의 최소값(ceilng)은 9.5% 밖에 되지 않는다. 이런 경우, 개 이미지에 대한 성능을 향상시키는 것은 작업 시간에 비해 큰 효과를 가져오지 못한다.\n",
        "- Evaluate multiple ideas in parallel\n",
        "    - Ideas for cat detection\n",
        "        - Fix pictures of dogs being recognized as cats\n",
        "        - Fix great cats (lions, panthers, etc…) being misrecognized\n",
        "        - Improve performance on blurry images\n",
        "    - 고양이로 분류하지 못한 이미지들과 그 이유에 대한 표를 다음과 같이 작성하면, classifier의 성능을 향상시키기 위해 어떻게 접근해야 하는지 파악할 수 있다.\n",
        "\n",
        "\n",
        "| Image | Dog  | Great Cats | Blurry | Instagram filters | Comments |\n",
        "| :---: | :--: | :---:      | :--:   | :--:              | ----- |\n",
        "| 1     | ✓    |            |        |                  ✓| Pitbull|\n",
        "| 2     | ✓    |            |      ✓ |  ✓                |       |\n",
        "| 3     |      |            |        |                   | Rainy day at zoo |\n",
        "| 4     |      |  ✓         |        |                   |           |\n",
        "| ...   |      |            |        |                   |           |\n",
        "| % totals | 8%| 43%        | 61%    | 12%\t| |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvqK742MF-ES"
      },
      "source": [
        "### Cleaning Up Incorrectly Labeled Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iul_fXSbSKwp"
      },
      "source": [
        "- Incorrectly labeled exmaple을 발견한 경우 어떻게 해야 할까?\n",
        "- DL algorithms are quite robust to random errors in the training set. 따라서 training set의 random error을 fix하기 위해 너무 많은 시간을 들이지 않아도 된다.\n",
        "- 하지만 DL algorithm은 systematic error에 대해서는 robust 하지 않다.\n",
        "- Dev set이나 test set에서 incorrectly labeled example을 발견한 경우는 어떻게 해야 될까?\n",
        "- Error analysis 표에 ‘incorrectly labled’ column을 추가해, incorrectly labled eample의 비율이 큰 편이라면, fix한다.\n",
        "- Correcting incorrect dev/test set examples\n",
        "    - Apply same process to your dev and test sets to make sure they continue to com from the same distribution\n",
        "    - Consider examining examples your algorithm got right as well as ones it got wrong.\n",
        "    - Train and dev/test data may now come from slightly different distributions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JHO5TWXF-Gj"
      },
      "source": [
        "### Build your First System Quickly, then Iterate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0xc_AhGTZZL"
      },
      "source": [
        "- Guideline: build your first system quickly, then iterate\n",
        "    - Set up dev/test set and metric\n",
        "    - Build initial system quickly\n",
        "    - User bias/variance analysis & error analysis to prioritize next steps.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH1dOItmF-Jc"
      },
      "source": [
        "### Training and Testing on Different Distributions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw9AKUEO3Iw-"
      },
      "source": [
        "- Cat app example\n",
        "    - 예를 들어, 모바일에서 고양이를 분류해내는 classifier를 학습시킬 때, 모바일 이미지만을 이용하면 좋지만 획득할 수 있는 이미지의 수가 적다. 하지만 웹 이미지는 충분히 획득할 수 있기 때문에 웹 이미지를 이용할 수 밖에 없을 것이다. (웹 이미지는 모바일 이미지에 비해 너무 해상도가 좋다.) 어떻게 해야 할까?\n",
        "    - Option 1: train, dev, test et에 웹 이미지와 모바일 이미지를 동일한 비율로 사용하는 것. 이 경우 웹 이미지의 비율이 너무 높기 때문에 권장하지 않는다.\n",
        "    - Option 2: dev, test set 에는 모바일 이미지만 사용\n",
        "- Speech recognition example: speech activated rearview mirror\n",
        "    - Training set: purchased data, smart speaker control, voice keyboard (about 500,000)\n",
        "    - Dev/test: speech activated rearview mirror (about 20,000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJD8QEk4F-Li"
      },
      "source": [
        "### Bias and Variance with Mismatched Data Distributions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNi_8LjWQMgX"
      },
      "source": [
        "- Cat classifier example\n",
        "    - Assume humans get ~0% error.\n",
        "    - Training error: 1%; dev error: 10%\n",
        "    - Train data set 과 dev data set이 동일한 distritution으로 부터 왔다면, high variance problem이라고 말할 수 있을 것이다. 하지만 distribution이 다르다면?\n",
        "    - Training-dev set: same distribution as training set, but not used for training\n",
        "    - Training error: 1%; training-dev error: 9%; dev error: 10% — hight variance problem\n",
        "    - Training error: 1%; training-dev error: 1.5%; dev error: 10% — data mismatch problem\n",
        "    - Human error: 0%; training error: 10%; training-dev error: 11%; dev error: 12% — avoidable bias problem\n",
        "    - Human error: 0%; training error: 10%; training-dev error: 11%; dev error: 20% — avoidable bias problem and data mismatch problem\n",
        "- Degree of overfitting to the dev set: test error - dev error\n",
        "- More general formuation (speech activated rearview mirror)\n",
        "\n",
        "|             | General speech | rearview mirror speech |\n",
        "| ----        | :----         |     :----             |\n",
        "| Human error | **4%**             |       6%               |\n",
        "| Trained     | **7% (training error)** |       6%          |\n",
        "| Not-Trained | **10% (training-dev error)** |   **6% (dev/test error)**     |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cApWr6q1SVyk"
      },
      "source": [
        "### Addressing Data Mismatch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKQaeVfVTxR8"
      },
      "source": [
        "- Addressing data mismatch\n",
        "    - Carry out manual error analysis to try to understand difference between training and dev/test sets\n",
        "    - Make training data more similar; or collect more data similar to dev/test sets\n",
        "- Artificial data synthesis (one method of making training data more similar)\n",
        "    - 예를 들어, 음성과 nosis를 합성. 여기서 주의할 점은 만약 합성된 음성에서 noise가 반복된다면 noise가 overfitting 될 수 있다는 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYm9-qsHSV1m"
      },
      "source": [
        "### Transfer Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BB3CPtCdb7C"
      },
      "source": [
        "- Transfer learning: 어떤 목적을 위해 학습된 network를 다른 목적을 위해 사용할 수 있다.\n",
        "- 예를 들어, cat classifier를 radiology diagnosis의 학습을 위해서도 이용할 수 있다.\n",
        "    - cat classifier의 last layer를 제거하나, randomly initialized layer를 추가해, last layer만을 학습시킨다.\n",
        "- Rul of thumb\n",
        "    - Small data: retrain only last layer (output layer)\n",
        "    - Large data: retrain all the layers\n",
        "- 이전에 train된 상태를 ‘pre-trained’라고도 말하고, 다시 retrain하는 것을 fine tuning이라고도 말한다.\n",
        "- When transfer learning makes sense (transfer from A to B)\n",
        "    - Task A and B have the same input x.\n",
        "    - You have a lot more data for Task A than Task B.\n",
        "    - Low level features from A could be helpful for learning B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9c2hrsUSV5F"
      },
      "source": [
        "### Multi-task Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUxIUayq3tXW"
      },
      "source": [
        "- Muti-task learning은 여러 다른 학습을 동시에 하는 것이다.\n",
        "- 예를 들어, 보행자, 자동차, 정지 표지판, 신호등을 인식해야 하는 image recognition 시스템을 생각해보자. 4가지에 대해 각각 network를 만드는 것보다 하나의 network에서 4가지를 모두 인식할 수 있도록 만다는 것이 더 좋은 성능을 발휘한다.\n",
        "- 이러한 경우의 cost function은 다음과 같다(softmax와는 다르다): $(1/m)\\sum_i^m \\sum_j^4 (logistic~loss)_j^{(i)}$\n",
        "- 이러한 방식은 Label을 가지지 않은 데이터에 대해서도 적용할 수 있는데, 이러한 경우의 cost function을 계산할 때는, $j$에 대한 합을 구할 때, labeling되지 않는 것은 제외하면 된다.\n",
        "- When multi-task learning makes sense\n",
        "    - Training on a set of tasks that could benefit from having shared lower-level features.\n",
        "    - Usually, amount of data you have for each task is quite similar.\n",
        "    - Can train a big enough network to do well on all the tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prYPb7o2SV9w"
      },
      "source": [
        "### What is End-to-end Deep Learning?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU3HuNkjFthg"
      },
      "source": [
        "- 여러 단계를 거쳐 학습을 하는 시스템도 있지만, 단계를 거치지 않고 곧 바로 학습을 하는 것을 end-to-end learning 이라고 한다.\n",
        "- Example\n",
        "    - Audio — Features — Phonemes — Word — Transcript\n",
        "    - E2E deep learning: Audo —— Transcript\n",
        "- Big data set이 가능한 경우에는 E2E deep learning이 좋지만, 그렇지 않은 경우에는 일반적인 단계별 학습이 더 유리하다\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-GummE0SWA_"
      },
      "source": [
        "### Whether to use End-to-end Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM57VEAXkI6L"
      },
      "source": [
        "- Pros and cons of end-to-end deep learning\n",
        "    - Props:\n",
        "        - Let the data speak: 인간의 선입견에 영향을 받지 않고 데이터 그 자체를 학습할 수 있다.\n",
        "        - Less hand-designing of components needed\n",
        "    - Cons:\n",
        "        - May need large amount of data\n",
        "        - Excludes potentially useful hand-design components \n",
        "- Applying end-to-end deep learning\n",
        "    - Key question: Do you have sufficient data to learn a function of the complexity needed to map x to y?\n",
        "    - Use DL to learn some individual components.\n",
        "    - Carefully choose X->Y depending on what task you can get data for.\n"
      ]
    }
  ]
}
